{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c9f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e7e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install deepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdf76eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('happy boy.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9edf7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3499721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img) ##(BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de01817",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dde2066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace ##pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f10ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install deepface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39879da2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = DeepFace.analyze(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a09dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63c07f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]['dominant_emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7670be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd81337",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "#print (faceCascade.empty()) \n",
    "\n",
    "faces = faceCascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "#Draw a rectangle around the faces \n",
    "for(x, y, w, h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),10)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121d9cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.putText(img ,predictions[0]['dominant_emotion'],(50,50), cv2.FONT_HERSHEY_COMPLEX , 2, (0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb34016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1194cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('sad girl2.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14c3c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcbee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b797fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = DeepFace.analyze(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635b38ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bcbb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]['dominant_emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2dec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2de6cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY) \n",
    "#print (faceCascade.empty()) \n",
    "\n",
    "faces = faceCascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "#Draw a rectangle around the faces \n",
    "for(x, y, w, h) in faces:\n",
    "    cv2.rectangle(img1,(x,y),(x+w,y+h),(255,20,150),3)\n",
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d650bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54004515",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.putText(img1 ,predictions[0]['dominant_emotion'],(`), cv2.FONT_HERSHEY_COMPLEX , 2, (0,191,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce6e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.imread('suprised.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d01105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c1010",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47397b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = DeepFace.analyze(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec77a2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4136f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]['dominant_emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f930e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6118aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray1 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) \n",
    "#print (faceCascade.empty()) \n",
    "\n",
    "faces = faceCascade.detectMultiScale(gray1,1.1,4)\n",
    "\n",
    "#Draw a rectangle around the faces \n",
    "for(x, y, w, h) in faces:\n",
    "    cv2.rectangle(img2,(x,y),(x+w,y+h),(0,400,255),3)\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc01593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf665337",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.putText(img2 ,predictions[0]['dominant_emotion'],(90,275), cv2.FONT_HERSHEY_COMPLEX , 2, (0,0,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091943dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8311c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = cv2.imread('sad girl.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456e6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44732c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img3, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55deeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = DeepFace.analyze(img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8133e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]['dominant_emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c32c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7272b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray1 = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY) \n",
    "#print (faceCascade.empty()) \n",
    "\n",
    "faces = faceCascade.detectMultiScale(gray1,1.1,4)\n",
    "\n",
    "#Draw a rectangle around the faces \n",
    "for(x, y, w, h) in faces:\n",
    "    cv2.rectangle(img3,(x,y),(x+w,y+h),(255,255,255),3)\n",
    "plt.imshow(img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1049d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img3, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204f6b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.putText(img3 ,predictions[0]['dominant_emotion'],(50,50), cv2.FONT_HERSHEY_COMPLEX , 2, (255,255,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c61448",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img3, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c5c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img4 = cv2.imread('angary man.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513e3167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b09087",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img4, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f1a538",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = DeepFace.analyze(img4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad59e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26457993",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]['dominant_emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ad022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray1 = cv2.cvtColor(img4, cv2.COLOR_BGR2GRAY) \n",
    "#print (faceCascade.empty()) \n",
    "\n",
    "faces = faceCascade.detectMultiScale(gray1,1.1,4)\n",
    "\n",
    "#Draw a rectangle around the faces \n",
    "for(x, y, w, h) in faces:\n",
    "    cv2.rectangle(img4,(x,y),(x+w,y+h),(255,255,255),3)\n",
    "plt.imshow(img4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ec46d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img4, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d754345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.putText(img4 ,predictions[0]['dominant_emotion'],(50,50), cv2.FONT_HERSHEY_COMPLEX , 2, (0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a61394",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img4, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3410d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import ImageTk, Image\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "def open_file():\n",
    "    global selected_image  # access the global variable\n",
    "    filepath = filedialog.askopenfilename(filetypes=[(\"Image Files\", \"*.jpg; *.jpeg; *.png\")])\n",
    "    if filepath:\n",
    "        image = Image.open(filepath)\n",
    "        image = image.resize((300, 300)) # Resize the image to fit the window\n",
    "        photo = ImageTk.PhotoImage(image)\n",
    "        image_label.configure(image=photo)\n",
    "        image_label.image = photo # Store a reference to the photo to avoid garbage collection\n",
    "        selected_image = filepath  # assign the selected image to the global variable\n",
    "\n",
    "def analyze():\n",
    "    global selected_image  # access the global variable\n",
    "    if selected_image:\n",
    "        print(selected_image)\n",
    "        image = cv2.imread(selected_image)\n",
    "        predictions = DeepFace.analyze(image)\n",
    "        print(predictions)\n",
    "        ans = predictions[0]['dominant_emotion']\n",
    "\n",
    "        # Set the color based on the emotion\n",
    "        if ans == 'happy':\n",
    "            text_color = 'green'\n",
    "            rectangle_color = (0, 255, 0)  # Green RGB color\n",
    "        elif ans == 'sad':\n",
    "            text_color = 'blue'\n",
    "            rectangle_color = (255, 0, 0)  # Blue RGB color\n",
    "        elif ans == 'angry':\n",
    "            text_color = 'red'\n",
    "            rectangle_color = (0, 0, 255)  # Red RGB color\n",
    "        else:\n",
    "            text_color = 'black'\n",
    "            rectangle_color = (255, 255, 255)  # White RGB color\n",
    "\n",
    "        label_Prediction = tk.Label(root, text=ans, bg='white', font=result_font, fg=text_color)  # assign the custom font and text color\n",
    "        canvas1.create_window(250, 250, window=label_Prediction)\n",
    "\n",
    "        # Open the image with OpenCV and draw a rectangle around the face\n",
    "        #image = cv2.imread(selected_image)\n",
    "        face_coords = predictions['region']\n",
    "        x1, y1, x2, y2 = face_coords['x'], face_coords['y'], face_coords['x']+face_coords['w'], face_coords['y']+face_coords['h']\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), rectangle_color, 2)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert the image to RGB for displaying in tkinter\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((300, 300))\n",
    "        photo = ImageTk.PhotoImage(image)\n",
    "        image_label.configure(image=photo)\n",
    "        image_label.image = photo\n",
    "\n",
    "    else:\n",
    "        print(\"No image selected\")\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "canvas1 = tk.Canvas(root, width=500, height=300)\n",
    "canvas1.pack()\n",
    "\n",
    "label1 = tk.Label(root, text='Face Emotion Detection and Recommendation App', bg='light green',)\n",
    "canvas1.create_window(250, 20, window=label1)\n",
    "\n",
    "button1 = tk.Button(root, text='Please upload photo', command=open_file, bg='yellow',)\n",
    "canvas1.create_window(250, 190, window=button1)\n",
    "\n",
    "image_label = tk.Label(root)\n",
    "canvas1.create_window(250, 150, window=image_label)\n",
    "\n",
    "# Create a custom font\n",
    "#custom_font = tk.font.Font(family='Arial', size=12, weight='bold')\n",
    "custom_font = ('Arial', 12, 'bold')\n",
    "\n",
    "# Create a button with the custom font\n",
    "def open_help_file():\n",
    "    file_path = \"help.txt\"  # Replace with the actual file path\n",
    "    if os.path.exists(file_path):\n",
    "        os.startfile(file_path)\n",
    "    else:\n",
    "        print(\"Help file not found.\")\n",
    "\n",
    "button = tk.Button(root, text='Need help?', font=custom_font, fg='#856ff8', command=open_help_file)\n",
    "button.pack()\n",
    "\n",
    "\n",
    "canvas1.configure(bg='skyblue2')\n",
    "\n",
    "# Create a custom font for the analysis result\n",
    "result_font = ('Arial', 16, 'bold')\n",
    "#result_font = tk.font.Font(family='Arial', size=16, weight='bold')\n",
    "\n",
    "\n",
    "button2 = tk.Button(root, text='Analyze the emotion', command=analyze, bg='dark orange')\n",
    "canvas1.create_window(250, 280, window=button2)\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c58cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import ImageTk, Image\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "def open_file():\n",
    "    global selected_image  # access the global variable\n",
    "    filepath = filedialog.askopenfilename(filetypes=[(\"Image Files\", \"*.jpg; *.jpeg; *.png\")])\n",
    "    if filepath:\n",
    "        image = Image.open(filepath)\n",
    "        image = image.resize((300, 300)) # Resize the image to fit the window\n",
    "        photo = ImageTk.PhotoImage(image)\n",
    "        image_label.configure(image=photo)\n",
    "        image_label.image = photo # Store a reference to the photo to avoid garbage collection\n",
    "        selected_image = filepath  # assign the selected image to the global variable\n",
    "\n",
    "def analyze():\n",
    "    global selected_image,detected_emotion  # access the global variable\n",
    "    if selected_image:\n",
    "        print(selected_image)\n",
    "        image = cv2.imread(selected_image)\n",
    "        predictions = DeepFace.analyze(image)\n",
    "        print(predictions)\n",
    "        ans = predictions[0]['dominant_emotion']\n",
    "        detected_emotion = ans\n",
    "\n",
    "        # Set the color based on the emotion\n",
    "        if ans == 'happy':\n",
    "            text_color = 'green'\n",
    "            rectangle_color = (0, 255, 0)  # Green RGB color\n",
    "        elif ans == 'sad':\n",
    "            text_color = 'purple'\n",
    "            rectangle_color = (255,20,150)  # Blue violet RGB color\n",
    "        elif ans == 'angry':\n",
    "            text_color = 'red'\n",
    "            rectangle_color = (0, 0, 255)  # Red RGB color\n",
    "        elif ans == 'neutral':\n",
    "            text_color = 'black'\n",
    "            rectangle_color = (255, 255, 255)  # White RGB color\n",
    "        elif ans == 'fear':\n",
    "            text_color = 'yellow'\n",
    "            rectangle_color = (0, 400, 255)  # yellow RGB color\n",
    "        else:\n",
    "            text_color = 'orange'\n",
    "            rectangle_color = (0,191,255)  # orange RGB color   \n",
    "                  \n",
    "            \n",
    "        label_Prediction = tk.Label(root, text=ans, bg='white', font=result_font, fg=text_color)  # assign the custom font and text color\n",
    "        canvas1.create_window(250, 250, window=label_Prediction)\n",
    "\n",
    "        # Open the image with OpenCV and draw a rectangle around the face\n",
    "        #image = cv2.imread(selected_image)\n",
    "        face_coords = predictions[0]['region']\n",
    "        x1, y1, x2, y2 = face_coords['x'], face_coords['y'], face_coords['x']+face_coords['w'], face_coords['y']+face_coords['h']\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), rectangle_color, 2)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert the image to RGB for displaying in tkinter\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((300, 300))\n",
    "        photo = ImageTk.PhotoImage(image)\n",
    "        image_label.configure(image=photo)\n",
    "        image_label.image = photo\n",
    "\n",
    "    else:\n",
    "        print(\"No image selected\")\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "canvas1 = tk.Canvas(root, width=500, height=350)\n",
    "canvas1.pack()\n",
    "\n",
    "label1 = tk.Label(root, text='Face Emotion Detection and Recommendation App', bg='light green',)\n",
    "canvas1.create_window(250, 20, window=label1)\n",
    "\n",
    "button1 = tk.Button(root, text='Please upload photo', command=open_file, bg='yellow',)\n",
    "canvas1.create_window(250, 190, window=button1)\n",
    "\n",
    "image_label = tk.Label(root)\n",
    "canvas1.create_window(250, 150, window=image_label)\n",
    "\n",
    "# Create a custom font\n",
    "#custom_font = tk.font.Font(family='Arial', size=12, weight='bold')\n",
    "custom_font = ('Arial', 12, 'bold')\n",
    "\n",
    "import os\n",
    "\n",
    "def open_help_file():\n",
    "    file_path = \"mid term presentation by Ayush srivastava.pptx\"  # Replace with the actual file path\n",
    "    if os.path.exists(file_path):\n",
    "        os.startfile(file_path)\n",
    "    else:\n",
    "        print(\"Help file not found.\")\n",
    "# Create a button with the custom font\n",
    "button = tk.Button(root, text='Need help?', font=custom_font,command=open_help_file, fg='#856ff8')\n",
    "button.pack()\n",
    "\n",
    "canvas1.configure(bg='skyblue2')\n",
    "\n",
    "# Create a custom font for the analysis result\n",
    "result_font = ('Arial', 16, 'bold')\n",
    "#result_font = tk.font.Font(family='Arial', size=16, weight='bold')\n",
    "\n",
    "\n",
    "button2 = tk.Button(root, text='Analysee the emotion', command=analyze, bg='dark orange')\n",
    "canvas1.create_window(250, 280, window=button2)\n",
    "\n",
    "def get_happy_recommendations():\n",
    "    # Retrieve recommendations for happy emotion\n",
    "    recommendations = [\"Watch a comedy movie\", \"Listen to upbeat music\", \"Go for a walk in nature\"]\n",
    "    return recommendations\n",
    "\n",
    "def get_sad_recommendations():\n",
    "    # Retrieve recommendations for sad emotion\n",
    "    recommendations = [\"Watch a heartwarming movie\", \"Listen to soothing music\", \"talk to a friend or family about your feelings\"]\n",
    "    return recommendations\n",
    "\n",
    "def get_angry_recommendations():\n",
    "    # Retrieve recommendations for angry emotion\n",
    "    recommendations = [\"Practice deep breathing exercises\", \"Engage in physical activity\", \"Try meditation or mindfulness\"]\n",
    "    return recommendations\n",
    "\n",
    "def get_surprised_recommendations():\n",
    "    # Retrieve recommendations for surprised emotion\n",
    "    recommendations = [\"clam your self \", \"analyse the stiuation\", \"enjoy the movement!!\"]\n",
    "    return recommendations\n",
    "\n",
    "def get_fear_recommendations():\n",
    "    # Retrieve recommendations for fear emotion\n",
    "    recommendations = [\"clam your self\",\"make ur self feel safe\",\"take deep breaths\",\"face your fears\"]\n",
    "    return recommendations\n",
    "\n",
    "def get_default_recommendations():\n",
    "    # Retrieve default recommendations applicable to any emotion\n",
    "    recommendations = [\"do what you like\", \"Read a good book\", \"Spend time with loved ones\",\"go on trip or an outing\"]\n",
    "    return recommendations\n",
    "       \n",
    "\n",
    "\n",
    "# Function to generate recommendations based on detected emotion\n",
    "def generate_recommendations(emotion):\n",
    "    if emotion == \"happy\":\n",
    "        recommendations = get_happy_recommendations()\n",
    "    elif emotion == \"sad\":\n",
    "        recommendations = get_sad_recommendations()\n",
    "    elif emotion == \"angry\":\n",
    "        recommendations = get_angry_recommendations()\n",
    "    elif emotion == \"surprise\":\n",
    "           recommendations = get_angry_recommendations()\n",
    "    elif emotion == \"fear\":\n",
    "        recommendations = get_fear_recommendations()\n",
    "    else:\n",
    "        recommendations = get_default_recommendations()\n",
    "        \n",
    "    # Display the recommendations in a new window\n",
    "    recommendations_window = tk.Toplevel(root)\n",
    "    recommendations_window.title('Recommendations')\n",
    "    recommendations_window.geometry('400x300')\n",
    "    recommendations_window.configure(bg=\"white\")\n",
    "\n",
    "    label_recommendations = tk.Label(recommendations_window, text='Recommendations:', bg='white', font=result_font)\n",
    "    label_recommendations.pack(pady=10)\n",
    "\n",
    "    for index, recommendation in enumerate(recommendations):\n",
    "        label_recommendation = tk.Label(recommendations_window, text=f'{index + 1}. {recommendation}', bg='white')\n",
    "        label_recommendation.pack()\n",
    "\n",
    "    recommendations_window.mainloop()\n",
    "\n",
    "# ...\n",
    "\n",
    "button3 = tk.Button(root, text='Get Recommendations', command=lambda: generate_recommendations(detected_emotion), bg='cyan')\n",
    "canvas1.create_window(250, 320, window=button3)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88cd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca9237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
